{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.911547</td>\n",
       "      <td>0.848781</td>\n",
       "      <td>2.058419</td>\n",
       "      <td>-0.369295</td>\n",
       "      <td>0.534314</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>0.606555</td>\n",
       "      <td>0.202376</td>\n",
       "      <td>-0.557390</td>\n",
       "      <td>-0.821807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771490</td>\n",
       "      <td>-0.540937</td>\n",
       "      <td>-0.460555</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>-0.516034</td>\n",
       "      <td>0.063451</td>\n",
       "      <td>0.055119</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>0.462376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.192671</td>\n",
       "      <td>12.785971</td>\n",
       "      <td>-9.906650</td>\n",
       "      <td>3.320337</td>\n",
       "      <td>-4.801176</td>\n",
       "      <td>5.760059</td>\n",
       "      <td>-18.750889</td>\n",
       "      <td>-37.353443</td>\n",
       "      <td>-0.391540</td>\n",
       "      <td>-5.052502</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>5.303607</td>\n",
       "      <td>-0.639435</td>\n",
       "      <td>0.263203</td>\n",
       "      <td>-0.108877</td>\n",
       "      <td>1.269566</td>\n",
       "      <td>0.939407</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.193670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.376472</td>\n",
       "      <td>0.074030</td>\n",
       "      <td>-0.557307</td>\n",
       "      <td>-1.619405</td>\n",
       "      <td>0.106406</td>\n",
       "      <td>-0.125209</td>\n",
       "      <td>0.073170</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>-0.780447</td>\n",
       "      <td>0.069638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459547</td>\n",
       "      <td>-0.094690</td>\n",
       "      <td>-1.216613</td>\n",
       "      <td>-0.673362</td>\n",
       "      <td>-0.215961</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.066803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276672</td>\n",
       "      <td>0.445987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.356348</td>\n",
       "      <td>1.746360</td>\n",
       "      <td>-6.374624</td>\n",
       "      <td>1.772205</td>\n",
       "      <td>-3.439294</td>\n",
       "      <td>1.457811</td>\n",
       "      <td>-0.362577</td>\n",
       "      <td>1.443791</td>\n",
       "      <td>-1.927359</td>\n",
       "      <td>-6.564659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.964817</td>\n",
       "      <td>-0.619437</td>\n",
       "      <td>-1.732613</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>1.130828</td>\n",
       "      <td>0.415703</td>\n",
       "      <td>1</td>\n",
       "      <td>9.863900</td>\n",
       "      <td>0.637343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.234922</td>\n",
       "      <td>0.355413</td>\n",
       "      <td>1.972183</td>\n",
       "      <td>-1.255593</td>\n",
       "      <td>-0.681387</td>\n",
       "      <td>-0.665732</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>-0.003153</td>\n",
       "      <td>1.122451</td>\n",
       "      <td>-1.481246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912107</td>\n",
       "      <td>-0.286338</td>\n",
       "      <td>0.451208</td>\n",
       "      <td>0.188315</td>\n",
       "      <td>-0.531846</td>\n",
       "      <td>0.123185</td>\n",
       "      <td>0.039581</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.471810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1         V2        V3        V4        V5        V6         V7  \\\n",
       "0  -0.911547   0.848781  2.058419 -0.369295  0.534314  0.293869   0.606555   \n",
       "1 -13.192671  12.785971 -9.906650  3.320337 -4.801176  5.760059 -18.750889   \n",
       "2   0.376472   0.074030 -0.557307 -1.619405  0.106406 -0.125209   0.073170   \n",
       "3  -2.356348   1.746360 -6.374624  1.772205 -3.439294  1.457811  -0.362577   \n",
       "4  -0.234922   0.355413  1.972183 -1.255593 -0.681387 -0.665732   0.059110   \n",
       "\n",
       "          V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0   0.202376 -0.557390 -0.821807  ...  0.771490 -0.540937 -0.460555  0.830709   \n",
       "1 -37.353443 -0.391540 -5.052502  ... -8.887017  5.303607 -0.639435  0.263203   \n",
       "2   0.023187 -0.780447  0.069638  ...  0.459547 -0.094690 -1.216613 -0.673362   \n",
       "3   1.443791 -1.927359 -6.564659  ...  0.621203  0.964817 -0.619437 -1.732613   \n",
       "4  -0.003153  1.122451 -1.481246  ...  0.912107 -0.286338  0.451208  0.188315   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
       "0 -0.516034  0.063451  0.055119      0      -0.013973     0.462376  \n",
       "1 -0.108877  1.269566  0.939407      1      -0.293440    -0.193670  \n",
       "2 -0.215961  0.001256  0.066803      0       0.276672     0.445987  \n",
       "3  0.108361  1.130828  0.415703      1       9.863900     0.637343  \n",
       "4 -0.531846  0.123185  0.039581      1      -0.293440    -0.471810  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/cleaned_creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into dependent and independent features\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the values into an array for feeding the classification algorithms.\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building\n",
    "1. Logistic Regression\n",
    "2. KNN\n",
    "3. SVC\n",
    "4. DecisionTreeClassifier\n",
    "5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"SupportVectorClassifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression()  : Training accuracy score is 93.0 %\n",
      "\n",
      "KNeighborsClassifier()  : Training accuracy score is 92.0 %\n",
      "\n",
      "SVC()  : Training accuracy score is 93.0 %\n",
      "\n",
      "DecisionTreeClassifier()  : Training accuracy score is 91.0 %\n",
      "\n",
      "RandomForestClassifier()  : Training accuracy score is 93.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(x_train,y_train)\n",
    "    training_score = cross_val_score(classifier, x_train, y_train,cv=10)\n",
    "    print()\n",
    "    print(classifier, \" : Training accuracy score is\", round(training_score.mean(),2)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()  : Prediction accuracy score is 52.0 %\n",
      "KNeighborsClassifier()  : Prediction accuracy score is 53.0 %\n",
      "SVC()  : Prediction accuracy score is 51.0 %\n",
      "DecisionTreeClassifier()  : Prediction accuracy score is 54.0 %\n",
      "RandomForestClassifier()  : Prediction accuracy score is 52.0 %\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    prediction_score = classifier.predict(x_test)\n",
    "    print(classifier, \" : Prediction accuracy score is\", round(prediction_score.mean(),2)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "Clearly we can see this is the case of overfitting. Here bias is hight but varience is low. This leads to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome overfitting, Lets use grid search cv for getting best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for log_reg: {'penalty': 'l1', 'C': 0.1}\n",
      "Best Parameters for knears_neighbors: {'n_neighbors': 3, 'algorithm': 'brute'}\n",
      "Best Parameters for svc: {'kernel': 'linear', 'C': 0.9}\n",
      "Best Parameters for tree_clf: {'min_samples_leaf': 6, 'max_depth': 3, 'criterion': 'gini'}\n",
      "Best Parameters for forest_clf: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 20}\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Cross Validation Score of LogisticRegression(C=0.1, penalty='l1', solver='liblinear') : \n",
      "-- 93.77%\n",
      "Cross Validation Score of KNeighborsClassifier(algorithm='brute', n_neighbors=3) : \n",
      "-- 92.88%\n",
      "Cross Validation Score of SVC(C=0.9, kernel='linear') : \n",
      "-- 92.63%\n",
      "Cross Validation Score of DecisionTreeClassifier(max_depth=3, min_samples_leaf=6) : \n",
      "-- 92.25%\n",
      "Cross Validation Score of RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                       n_estimators=200) : \n",
      "-- 93.27%\n",
      "\n",
      "================================================================\n",
      "Test Accuracy of LogisticRegression(C=0.1, penalty='l1', solver='liblinear') : \n",
      "-- 95.43%\n",
      "Test Accuracy of KNeighborsClassifier(algorithm='brute', n_neighbors=3) : \n",
      "-- 95.43%\n",
      "Test Accuracy of SVC(C=0.9, kernel='linear') : \n",
      "-- 95.43%\n",
      "Test Accuracy of DecisionTreeClassifier(max_depth=3, min_samples_leaf=6) : \n",
      "-- 93.91%\n",
      "Test Accuracy of RandomForestClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                       n_estimators=200) : \n",
      "-- 95.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'log_reg': LogisticRegression(solver='liblinear'),\n",
    "    'knears_neighbors': KNeighborsClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'tree_clf': DecisionTreeClassifier(),\n",
    "    'forest_clf': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "def bestparameter():\n",
    "    param_list = {\n",
    "        'log_reg': {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "        'knears_neighbors': {\"n_neighbors\": list(range(2, 5, 1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "        'svc': {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n",
    "        'tree_clf': {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2, 4, 1)),\n",
    "                     \"min_samples_leaf\": list(range(5, 7, 1))},\n",
    "        'forest_clf': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        random_search = RandomizedSearchCV(clf, param_distributions=param_list[clf_name], n_iter=10, cv=5,\n",
    "                                           scoring='accuracy', random_state=42)\n",
    "        random_search.fit(x_train, y_train)\n",
    "        print(f\"Best Parameters for {clf_name}: {random_search.best_params_}\")\n",
    "\n",
    "        # Update the best estimator in classifiers dictionary\n",
    "        classifiers[clf_name] = random_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "def validation_score():\n",
    "\n",
    "    print(\"\\n\\n==============================================================\")\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf_score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "        \n",
    "        print(f'Cross Validation Score of {clf} : \\n-- {round(clf_score.mean() * 100, 2)}%')\n",
    "    print(\"\\n================================================================\")\n",
    "\n",
    "    # Assuming x_test and y_test are your test data\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'Test Accuracy of {clf} : \\n-- {round(accuracy * 100, 2)}%')\n",
    "\n",
    "\n",
    "bestparameter()\n",
    "validation_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Fraud_TX.logger import logging\n",
    "from src.Fraud_TX.exception import customexception\n",
    "from src.Fraud_TX.utils.utils import save_object, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': {'training_accuracy': 1.0, 'testing_accuracy': 0.9593908629441624, 'model_filename': 'artifacts/RandomForestClassifier_Best_Model.pkl'}, 'KNeighborsClassifier': {'training_accuracy': 0.9504447268106735, 'testing_accuracy': 0.949238578680203, 'model_filename': 'artifacts/KNeighborsClassifier_Best_Model.pkl'}, 'SVC': {'training_accuracy': 0.9440914866581956, 'testing_accuracy': 0.9441624365482234, 'model_filename': 'artifacts/SVC_Best_Model.pkl'}, 'DecisionTreeClassifier': {'training_accuracy': 1.0, 'testing_accuracy': 0.9289340101522843, 'model_filename': 'artifacts/DecisionTreeClassifier_Best_Model.pkl'}, 'LogisticRegression': {'training_accuracy': 0.9504447268106735, 'testing_accuracy': 0.949238578680203, 'model_filename': 'artifacts/LogisticRegression_Best_Model.pkl'}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.Fraud_TX.logger import logging\n",
    "from src.Fraud_TX.exception import customexception\n",
    "\n",
    "def initiate_model_training(x_train, y_train, x_test, y_test):\n",
    "    try:\n",
    "        logging.info('Model Training stage started')\n",
    "\n",
    "        # Check if the 'artifacts' directory exists, and create it if not\n",
    "        artifacts_dir = 'artifacts'\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "\n",
    "        classifiers = {\n",
    "            \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "            \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "            \"LogisticRegression\": LogisticRegression(solver='liblinear')\n",
    "            # Add more classifiers as needed\n",
    "        }\n",
    "\n",
    "        results = {}  # Dictionary to store results\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            clf.fit(x_train, y_train)\n",
    "\n",
    "            # Get Training and Testing Accuracy\n",
    "            train_accuracy = clf.score(x_train, y_train)\n",
    "            test_accuracy = accuracy_score(y_test, clf.predict(x_test))\n",
    "\n",
    "            logging.info(f\"{clf_name} - Training Accuracy: {train_accuracy * 100:.2f}%, Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = f\"{artifacts_dir}/{clf_name}_Best_Model.pkl\"\n",
    "            joblib.dump(clf, model_filename)\n",
    "\n",
    "            results[clf_name] = {\n",
    "                'training_accuracy': train_accuracy,\n",
    "                'testing_accuracy': test_accuracy,\n",
    "                'model_filename': model_filename\n",
    "            }\n",
    "\n",
    "        logging.info(\"Model Training stage is completed\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error('Exception occurred at Model Training stage')\n",
    "        raise customexception(e, sys)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "results = initiate_model_training(x_train, y_train, x_test, y_test)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best Parameters from RandomizedSearchCV for RandomForestClassifier: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for RandomForestClassifier: 0.9365\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for KNeighborsClassifier: {'n_neighbors': 3, 'algorithm': 'brute'}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for KNeighborsClassifier: 0.9288\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for SVC: {'kernel': 'linear', 'C': 0.5}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for SVC: 0.9314\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for DecisionTreeClassifier: {'min_samples_leaf': 5, 'max_depth': 3, 'criterion': 'gini'}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for DecisionTreeClassifier: 0.9238\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for LogisticRegression: {'penalty': 'l1', 'C': 0.1}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for LogisticRegression: 0.9377\n",
      "\n",
      "RandomForestClassifier:\n",
      "  Training Accuracy: 1.0000\n",
      "  Testing Accuracy: 0.9594\n",
      "  Model Filename: artifacts/RandomForestClassifier_Best_Model.pkl\n",
      "\n",
      "KNeighborsClassifier:\n",
      "  Training Accuracy: 0.9568\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/KNeighborsClassifier_Best_Model.pkl\n",
      "\n",
      "SVC:\n",
      "  Training Accuracy: 0.9479\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/SVC_Best_Model.pkl\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "  Training Accuracy: 0.9504\n",
      "  Testing Accuracy: 0.9391\n",
      "  Model Filename: artifacts/DecisionTreeClassifier_Best_Model.pkl\n",
      "\n",
      "LogisticRegression:\n",
      "  Training Accuracy: 0.9416\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/LogisticRegression_Best_Model.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.Fraud_TX.logger import logging\n",
    "from src.Fraud_TX.exception import customexception\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def initiate_model_training(x_train, y_train, x_test, y_test):\n",
    "    try:\n",
    "        logging.info('Model Training stage started')\n",
    "\n",
    "        # Check if the 'artifacts' directory exists, and create it if not\n",
    "        artifacts_dir = 'artifacts'\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "\n",
    "        classifiers = {\n",
    "            \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "            \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "            \"LogisticRegression\": LogisticRegression(solver='liblinear')\n",
    "            # Add more classifiers as needed\n",
    "        }\n",
    "\n",
    "        results = {}  # Dictionary to store results\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            param_dist = get_param_dist(clf_name)\n",
    "\n",
    "            # Use RandomizedSearchCV for hyperparameter tuning\n",
    "            random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "            random_search.fit(x_train, y_train)\n",
    "\n",
    "            best_estimator = random_search.best_estimator_\n",
    "\n",
    "            # Get Training and Testing Accuracy\n",
    "            train_accuracy = best_estimator.score(x_train, y_train)\n",
    "            test_accuracy = accuracy_score(y_test, best_estimator.predict(x_test))\n",
    "\n",
    "            logging.info(f\"{clf_name} - Training Accuracy: {train_accuracy * 100:.2f}%, Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = f\"{artifacts_dir}/{clf_name}_Best_Model.pkl\"\n",
    "            joblib.dump(clf, model_filename)\n",
    "\n",
    "            # Save the best model from RandomizedSearchCV\n",
    "            joblib.dump(best_estimator, f\"artifacts/{clf_name}_Best_Model_RandomizedSearchCV.pkl\")\n",
    "\n",
    "            # Print additional information\n",
    "            print(f\"  Best Parameters from RandomizedSearchCV for {clf_name}: {random_search.best_params_}\")\n",
    "            print(f\"  Best Cross-Validated Accuracy from RandomizedSearchCV for {clf_name}: {random_search.best_score_:.4f}\")\n",
    "            print()\n",
    "\n",
    "            results[clf_name] = {\n",
    "                'training_accuracy': train_accuracy,\n",
    "                'testing_accuracy': test_accuracy,\n",
    "                'model_filename': model_filename\n",
    "            }\n",
    "\n",
    "        logging.info(\"Model Training stage is completed\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error('Exception occurred at Model Training stage')\n",
    "        raise customexception(e, sys)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "results = initiate_model_training(x_train, y_train, x_test, y_test)\n",
    "for clf_name, metrics in results.items():\n",
    "    print(f\"{clf_name}:\")\n",
    "    print(f\"  Training Accuracy: {metrics['training_accuracy']:.4f}\")\n",
    "    print(f\"  Testing Accuracy: {metrics['testing_accuracy']:.4f}\")\n",
    "    print(f\"  Model Filename: {metrics['model_filename']}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best Parameters from RandomizedSearchCV for RandomForestClassifier: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': None}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for RandomForestClassifier: 0.9352\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for KNeighborsClassifier: {'n_neighbors': 3, 'algorithm': 'brute'}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for KNeighborsClassifier: 0.9288\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for SVC: {'kernel': 'linear', 'C': 0.5}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for SVC: 0.9314\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for DecisionTreeClassifier: {'min_samples_leaf': 5, 'max_depth': 3, 'criterion': 'gini'}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for DecisionTreeClassifier: 0.9238\n",
      "\n",
      "  Best Parameters from RandomizedSearchCV for LogisticRegression: {'penalty': 'l1', 'C': 0.1}\n",
      "  Best Cross-Validated Accuracy from RandomizedSearchCV for LogisticRegression: 0.9377\n",
      "\n",
      "RandomForestClassifier:\n",
      "  Training Accuracy: 0.9949\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/RandomForestClassifier_Best_Model.pkl\n",
      "\n",
      "KNeighborsClassifier:\n",
      "  Training Accuracy: 0.9568\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/KNeighborsClassifier_Best_Model.pkl\n",
      "\n",
      "SVC:\n",
      "  Training Accuracy: 0.9479\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/SVC_Best_Model.pkl\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "  Training Accuracy: 0.9504\n",
      "  Testing Accuracy: 0.9391\n",
      "  Model Filename: artifacts/DecisionTreeClassifier_Best_Model.pkl\n",
      "\n",
      "LogisticRegression:\n",
      "  Training Accuracy: 0.9416\n",
      "  Testing Accuracy: 0.9543\n",
      "  Model Filename: artifacts/LogisticRegression_Best_Model.pkl\n",
      "\n",
      "Best Classifier: RandomForestClassifier\n",
      "Best Classifier Testing Accuracy: 0.9543\n",
      "Best Classifier Model Filename: artifacts/RandomForestClassifier_Best_Model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.Fraud_TX.logger import logging\n",
    "from src.Fraud_TX.exception import customexception\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def initiate_model_training(x_train, y_train, x_test, y_test):\n",
    "    try:\n",
    "        logging.info('Model Training stage started')\n",
    "\n",
    "        # Check if the 'artifacts' directory exists, and create it if not\n",
    "        artifacts_dir = 'artifacts'\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "\n",
    "        classifiers = {\n",
    "            \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "            \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "            \"SVC\": SVC(),\n",
    "            \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "            \"LogisticRegression\": LogisticRegression(solver='liblinear')\n",
    "            # Add more classifiers as needed\n",
    "        }\n",
    "\n",
    "        results = {}  # Dictionary to store results\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            param_dist = get_param_dist(clf_name)\n",
    "\n",
    "            # Use RandomizedSearchCV for hyperparameter tuning\n",
    "            random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "            random_search.fit(x_train, y_train)\n",
    "\n",
    "            best_estimator = random_search.best_estimator_\n",
    "\n",
    "            # Get Training and Testing Accuracy\n",
    "            train_accuracy = best_estimator.score(x_train, y_train)\n",
    "            test_accuracy = accuracy_score(y_test, best_estimator.predict(x_test))\n",
    "\n",
    "            logging.info(f\"{clf_name} - Training Accuracy: {train_accuracy * 100:.2f}%, Testing Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "            # Save the model\n",
    "            model_filename = f\"{artifacts_dir}/{clf_name}_Best_Model.pkl\"\n",
    "            joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "            # Save the best model from RandomizedSearchCV\n",
    "            joblib.dump(best_estimator, f\"artifacts/{clf_name}_Best_Model_RandomizedSearchCV.pkl\")\n",
    "\n",
    "            # Print additional information\n",
    "            print(f\"  Best Parameters from RandomizedSearchCV for {clf_name}: {random_search.best_params_}\")\n",
    "            print(f\"  Best Cross-Validated Accuracy from RandomizedSearchCV for {clf_name}: {random_search.best_score_:.4f}\")\n",
    "            print()\n",
    "\n",
    "            results[clf_name] = {\n",
    "                'training_accuracy': train_accuracy,\n",
    "                'testing_accuracy': test_accuracy,\n",
    "                'model_filename': model_filename\n",
    "            }\n",
    "\n",
    "        logging.info(\"Model Training stage is completed\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error('Exception occurred at Model Training stage')\n",
    "        raise customexception(e, sys)\n",
    "\n",
    "\n",
    "\n",
    "artifacts_dir = 'artifacts'\n",
    "if not os.path.exists(artifacts_dir):\n",
    "    os.makedirs(artifacts_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Call the function\n",
    "results = initiate_model_training(x_train, y_train, x_test, y_test)\n",
    "\n",
    "best_test_accuracy = 0.0\n",
    "best_clf_name = None\n",
    "\n",
    "for clf_name, metrics in results.items():\n",
    "    print(f\"{clf_name}:\")\n",
    "    print(f\"  Training Accuracy: {metrics['training_accuracy']:.4f}\")\n",
    "    print(f\"  Testing Accuracy: {metrics['testing_accuracy']:.4f}\")\n",
    "    print(f\"  Model Filename: {metrics['model_filename']}\")\n",
    "    print()\n",
    "\n",
    "    if metrics['testing_accuracy'] > best_test_accuracy:\n",
    "        best_test_accuracy = metrics['testing_accuracy']\n",
    "        best_clf_name = clf_name\n",
    "\n",
    "# Save only the best classifier\n",
    "best_model_filename = f\"{artifacts_dir}/{best_clf_name}_Best_Model.pkl\"\n",
    "best_model = joblib.load(results[best_clf_name]['model_filename'])\n",
    "joblib.dump(best_model, best_model_filename)\n",
    "\n",
    "print(f\"Best Classifier: {best_clf_name}\")\n",
    "print(f\"Best Classifier Testing Accuracy: {best_test_accuracy:.4f}\")\n",
    "print(f\"Best Classifier Model Filename: {best_model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
