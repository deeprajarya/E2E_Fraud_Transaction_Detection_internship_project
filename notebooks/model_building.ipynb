{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.364601</td>\n",
       "      <td>-0.350611</td>\n",
       "      <td>3.007412</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>0.194795</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>-0.749215</td>\n",
       "      <td>0.655023</td>\n",
       "      <td>0.655106</td>\n",
       "      <td>-0.839261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823843</td>\n",
       "      <td>-0.343019</td>\n",
       "      <td>-0.460763</td>\n",
       "      <td>0.634386</td>\n",
       "      <td>-0.376703</td>\n",
       "      <td>0.110085</td>\n",
       "      <td>0.085196</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181653</td>\n",
       "      <td>0.384086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.434004</td>\n",
       "      <td>3.225947</td>\n",
       "      <td>-6.596282</td>\n",
       "      <td>3.593161</td>\n",
       "      <td>-1.079452</td>\n",
       "      <td>-1.739741</td>\n",
       "      <td>-0.047420</td>\n",
       "      <td>0.301424</td>\n",
       "      <td>-1.779434</td>\n",
       "      <td>-5.836453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419178</td>\n",
       "      <td>0.157436</td>\n",
       "      <td>-0.714849</td>\n",
       "      <td>0.468859</td>\n",
       "      <td>-0.348522</td>\n",
       "      <td>0.420036</td>\n",
       "      <td>-0.327643</td>\n",
       "      <td>1</td>\n",
       "      <td>4.758611</td>\n",
       "      <td>0.529517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419326</td>\n",
       "      <td>-0.783233</td>\n",
       "      <td>1.376835</td>\n",
       "      <td>3.110438</td>\n",
       "      <td>-1.335870</td>\n",
       "      <td>-0.011701</td>\n",
       "      <td>-0.038907</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>-0.072302</td>\n",
       "      <td>0.310870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122397</td>\n",
       "      <td>-0.202255</td>\n",
       "      <td>0.956296</td>\n",
       "      <td>0.123122</td>\n",
       "      <td>-0.115909</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>0.103011</td>\n",
       "      <td>0</td>\n",
       "      <td>4.538531</td>\n",
       "      <td>-0.624902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.364601 -0.350611  3.007412  0.511529  0.194795  0.865765 -0.749215   \n",
       "1 -2.434004  3.225947 -6.596282  3.593161 -1.079452 -1.739741 -0.047420   \n",
       "2  0.419326 -0.783233  1.376835  3.110438 -1.335870 -0.011701 -0.038907   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.655023  0.655106 -0.839261  ...  0.823843 -0.343019 -0.460763  0.634386   \n",
       "1  0.301424 -1.779434 -5.836453  ... -0.419178  0.157436 -0.714849  0.468859   \n",
       "2  0.001432 -0.072302  0.310870  ... -0.122397 -0.202255  0.956296  0.123122   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
       "0 -0.376703  0.110085  0.085196      0       0.181653     0.384086  \n",
       "1 -0.348522  0.420036 -0.327643      1       4.758611     0.529517  \n",
       "2 -0.115909 -0.017333  0.103011      0       4.538531    -0.624902  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/cleaned_creditcard.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into dependent and independent features\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the values into an array for feeding the classification algorithms.\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building\n",
    "1. Logistic Regression\n",
    "2. KNN\n",
    "3. SVC\n",
    "4. DecisionTreeClassifier\n",
    "5. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression()  : Training accuracy score is 95.0 %\n",
      "\n",
      "KNeighborsClassifier()  : Training accuracy score is 93.0 %\n",
      "\n",
      "SVC()  : Training accuracy score is 94.0 %\n",
      "\n",
      "DecisionTreeClassifier()  : Training accuracy score is 89.0 %\n",
      "\n",
      "RandomForestClassifier()  : Training accuracy score is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(x_train,y_train)\n",
    "    training_score = cross_val_score(classifier, x_train, y_train,cv=10)\n",
    "    print()\n",
    "    print(classifier, \" : Training accuracy score is\", round(training_score.mean(),2)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()  : Prediction accuracy score is 53.0 %\n",
      "KNeighborsClassifier()  : Prediction accuracy score is 52.0 %\n",
      "SVC()  : Prediction accuracy score is 52.0 %\n",
      "DecisionTreeClassifier()  : Prediction accuracy score is 56.00000000000001 %\n",
      "RandomForestClassifier()  : Prediction accuracy score is 54.0 %\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    prediction_score = classifier.predict(x_test)\n",
    "    print(classifier, \" : Prediction accuracy score is\", round(prediction_score.mean(),2)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "Clearly we can see this is the case of overfitting. Here bias is hight but varience is low. This leads to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome overfitting, Lets use grid search cv for getting best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\iNeurOn_Projects\\E2E_CreditFraudDetection\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for log_reg: {'penalty': 'l1', 'C': 0.1}\n",
      "Best Parameters for knears_neighbors: {'n_neighbors': 3, 'algorithm': 'brute'}\n",
      "Best Parameters for svc: {'kernel': 'linear', 'C': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\iNeurOn_Projects\\E2E_CreditFraudDetection\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for tree_clf: {'min_samples_leaf': 5, 'max_depth': 3, 'criterion': 'entropy'}\n",
      "Best Parameters for forest_clf: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Cross Validation Score of LogisticRegression(C=0.1, penalty='l1', solver='liblinear') : \n",
      "-- 94.54%\n",
      "Cross Validation Score of KNeighborsClassifier(algorithm='brute', n_neighbors=3) : \n",
      "-- 93.39%\n",
      "Cross Validation Score of SVC(C=0.9, kernel='linear') : \n",
      "-- 94.92%\n",
      "Cross Validation Score of DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5) : \n",
      "-- 91.74%\n",
      "Cross Validation Score of RandomForestClassifier(max_depth=30, n_estimators=200) : \n",
      "-- 94.41%\n",
      "\n",
      "================================================================\n",
      "Test Accuracy of LogisticRegression(C=0.1, penalty='l1', solver='liblinear') : \n",
      "-- 91.88%\n",
      "Test Accuracy of KNeighborsClassifier(algorithm='brute', n_neighbors=3) : \n",
      "-- 93.91%\n",
      "Test Accuracy of SVC(C=0.9, kernel='linear') : \n",
      "-- 94.42%\n",
      "Test Accuracy of DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_leaf=5) : \n",
      "-- 91.37%\n",
      "Test Accuracy of RandomForestClassifier(max_depth=30, n_estimators=200) : \n",
      "-- 91.37%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'log_reg': LogisticRegression(solver='liblinear'),\n",
    "    'knears_neighbors': KNeighborsClassifier(),\n",
    "    'svc': SVC(),\n",
    "    'tree_clf': DecisionTreeClassifier(),\n",
    "    'forest_clf': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "def bestparameter():\n",
    "    param_list = {\n",
    "        'log_reg': {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "        'knears_neighbors': {\"n_neighbors\": list(range(2, 5, 1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
    "        'svc': {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n",
    "        'tree_clf': {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2, 4, 1)),\n",
    "                     \"min_samples_leaf\": list(range(5, 7, 1))},\n",
    "        'forest_clf': {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        random_search = RandomizedSearchCV(clf, param_distributions=param_list[clf_name], n_iter=10, cv=5,\n",
    "                                           scoring='accuracy', random_state=42)\n",
    "        random_search.fit(x_train, y_train)\n",
    "        print(f\"Best Parameters for {clf_name}: {random_search.best_params_}\")\n",
    "\n",
    "        # Update the best estimator in classifiers dictionary\n",
    "        classifiers[clf_name] = random_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "def validation_score():\n",
    "\n",
    "    print(\"\\n\\n==============================================================\")\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf_score = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "        \n",
    "        print(f'Cross Validation Score of {clf} : \\n-- {round(clf_score.mean() * 100, 2)}%')\n",
    "    print(\"\\n================================================================\")\n",
    "\n",
    "    # Assuming x_test and y_test are your test data\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Make predictions on the test set\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Evaluate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f'Test Accuracy of {clf} : \\n-- {round(accuracy * 100, 2)}%')\n",
    "\n",
    "\n",
    "bestparameter()\n",
    "validation_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
